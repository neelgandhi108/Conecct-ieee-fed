{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research_FederatedLearn(2Workers)-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmOgE6S8jNm-",
        "outputId": "5301a31d-9cf7-40c6-f987-14a91ea2599c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csbRMoeJ9l3l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2e0180e-789d-41aa-dc24-60d3e82b5844"
      },
      "source": [
        "!pip uninstall syft\n",
        "!pip install syft==0.2.9"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping syft as it is not installed.\u001b[0m\n",
            "Collecting syft==0.2.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/73/891ba1dca7e0ba77be211c36688f083184d8c9d5901b8cd59cbf867052f3/syft-0.2.9-py3-none-any.whl (433kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 18.5MB/s \n",
            "\u001b[?25hCollecting openmined.threepio==0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/38/df6367693c7f3808f076cd8c2647c434a04adda2bbb2435dadefe7258fd4/openmined.threepio-0.2.0.tar.gz (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.2)\n",
            "Collecting websocket-client~=0.57.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.8MB/s \n",
            "\u001b[?25hCollecting shaloop==0.2.1-alpha.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/8e/6c4493280d55199161c2eea896327c740195cf16cc74c5393c08eababc83/shaloop-0.2.1_alpha.11-py3-none-manylinux1_x86_64.whl (126kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 58.6MB/s \n",
            "\u001b[?25hCollecting lz4~=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/dacc3cbb33a9ded9e2e57f48707e8842f1080997901578ebddaa0e031646/lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 54.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (7.1.2)\n",
            "Collecting tblib~=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/de/dca3e651ca62e59c08d324f4a51467fa4b8cbeaafb883b5e83720b4d4a47/tblib-1.6.0-py2.py3-none-any.whl\n",
            "Collecting torchvision~=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 29.5MB/s \n",
            "\u001b[?25hCollecting phe~=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz\n",
            "Collecting importlib-resources~=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/2d/88f166bcaadc09d9fdbf1c336ad118e01b7fe1155e15675e125be2ff1899/importlib_resources-1.5.0-py2.py3-none-any.whl\n",
            "Collecting RestrictedPython~=5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/cc/28c4d966615a46b03be4dac0f2c6e713412efbf2f85428eeb9618c4f6f0c/RestrictedPython-5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n",
            "Collecting torch~=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 15kB/s \n",
            "\u001b[?25hCollecting aiortc==0.9.28\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c5/0c15e562c5ea1531e8c7db1bcd524e53619cc27a228f3f28d2ba55544d38/aiortc-0.9.28-cp37-cp37m-manylinux2010_x86_64.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 39.7MB/s \n",
            "\u001b[?25hCollecting notebook==5.7.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/36/89ebfffc9dd8c8dbd81c1ffb53e3d4233ee666414c143959477cb07cc5f5/notebook-5.7.8-py2.py3-none-any.whl (9.0MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0MB 55.5MB/s \n",
            "\u001b[?25hCollecting tornado==4.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/7b/e29ab3d51c8df66922fea216e2bddfcb6430fb29620e5165b16a216e0d3c/tornado-4.5.3.tar.gz (484kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 56.2MB/s \n",
            "\u001b[?25hCollecting websockets~=8.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.8MB/s \n",
            "\u001b[?25hCollecting flask-socketio~=4.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Collecting requests-toolbelt==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.3)\n",
            "Collecting syft-proto~=0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/88/67edf7836ac4eab723416933cd663c4f87753d3ff31337f91701c0b75474/syft_proto-0.5.3-py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hCollecting numpy~=1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.2MB/s \n",
            "\u001b[?25hCollecting psutil==5.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 55.4MB/s \n",
            "\u001b[?25hCollecting requests~=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from websocket-client~=0.57.0->syft==0.2.9) (1.15.0)\n",
            "Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.20)\n",
            "Requirement already satisfied: cffi>=1 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (1.14.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.10.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.4.1)\n",
            "Collecting aioice<0.7.0,>=0.6.17\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/86/e3cdf660b67da7a9a7013253db5db7cf786a52296cb40078db1206177698/aioice-0.6.18-py3-none-any.whl\n",
            "Collecting cryptography>=2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 50.2MB/s \n",
            "\u001b[?25hCollecting crc32c\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/85/4656cc0ac33be2725d6de41eabfeb72f86c194fe26decf28162d72f9a642/crc32c-2.2-cp37-cp37m-manylinux2010_x86_64.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting av<9.0.0,>=8.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 82kB/s \n",
            "\u001b[?25hCollecting pylibsrtp>=0.5.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/24/9c2060d5f2d831091c7bb41428d17fd20e839959f1e78e6930329b21c0a7/pylibsrtp-0.6.8-cp37-cp37m-manylinux2010_x86_64.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.8MB/s \n",
            "\u001b[?25hCollecting pyee>=6.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/0a/933b3931107e1da186963fd9bb9bceb9a613cff034cb0fb3b0c61003f357/pyee-8.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.10.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.9.4)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.0.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n",
            "Collecting python-socketio>=4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/15/70ce203227a6c21931e0a1a04552887e8f08f7556459d65e901674f026fc/python_socketio-5.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.12.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2020.12.5)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->importlib-resources~=1.5.0->syft==0.2.9) (3.7.4.3)\n",
            "Collecting netifaces\n",
            "  Downloading https://files.pythonhosted.org/packages/0d/18/fd6e9c71a35b67a73160ec80a49da63d1eed2d2055054cc2995714949132/netifaces-0.10.9.tar.gz\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook==5.7.8->syft==0.2.9) (1.1.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (2.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (3.3.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n",
            "Collecting bidict>=0.21.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/d4/eaf9242722bf991e0955380dd6168020cb15a71cc0d3cc2373f4911b1f1d/bidict-0.21.2-py2.py3-none-any.whl\n",
            "Collecting python-engineio>=4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/ff/8c5392bcc6beb31aaeb759fce5de2141ae79a86018ad0173008f76b26085/python_engineio-4.0.1-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->syft-proto~=0.5.2->syft==0.2.9) (54.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (2.4.7)\n",
            "Building wheels for collected packages: openmined.threepio, phe, tornado, psutil, netifaces\n",
            "  Building wheel for openmined.threepio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openmined.threepio: filename=openmined.threepio-0.2.0-cp37-none-any.whl size=80095 sha256=e99f878dba8878134b755ec5cea64ccf83d8289b1e91cd5407e1f8b771e5b7e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/a5/c5/7e67449f5d4d487e1d3a583ba51d27403b315b18ef2e48a13c\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=6e33c8b937ca2b38fdd8d0a0796f2034e77989d424b9535d133289af81e8e145\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/dc/36/dcb6bf0f1b9907e7b710ace63e64d08e7022340909315fdea4\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434001 sha256=3fefac1ee87279b4500875185e04c2bdb1243abfad288566faf9e48135c28e62\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/bf/f4/b68fa69596986881b397b18ff2b9af5f8181233aadcc9f76fd\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276421 sha256=827a3fa04ee95be4fd06c032ee9615b3ed915b51cd1eb2ce6096a9667c099938\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.10.9-cp37-cp37m-linux_x86_64.whl size=37421 sha256=971db29b2d5c3faa80325d0b3fb2dab815e620e1f528ff4ca01a1cd2268d8d30\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/8f/f3/7054578f04c904f70757c5c85a6e2823baa69d42365526e93d\n",
            "Successfully built openmined.threepio phe tornado psutil netifaces\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version >= \"3.0\", but you'll have notebook 5.7.8 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: bokeh 2.3.1 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: openmined.threepio, websocket-client, numpy, shaloop, lz4, tblib, torch, torchvision, phe, importlib-resources, RestrictedPython, netifaces, aioice, cryptography, crc32c, av, pylibsrtp, pyee, aiortc, tornado, notebook, websockets, bidict, python-engineio, python-socketio, flask-socketio, idna, requests, requests-toolbelt, syft-proto, psutil, syft\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: tblib 1.7.0\n",
            "    Uninstalling tblib-1.7.0:\n",
            "      Successfully uninstalled tblib-1.7.0\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: importlib-resources 5.1.2\n",
            "    Uninstalling importlib-resources-5.1.2:\n",
            "      Successfully uninstalled importlib-resources-5.1.2\n",
            "  Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Found existing installation: notebook 5.3.1\n",
            "    Uninstalling notebook-5.3.1:\n",
            "      Successfully uninstalled notebook-5.3.1\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed RestrictedPython-5.1 aioice-0.6.18 aiortc-0.9.28 av-8.0.3 bidict-0.21.2 crc32c-2.2 cryptography-3.4.7 flask-socketio-4.2.1 idna-2.8 importlib-resources-1.5.0 lz4-3.0.2 netifaces-0.10.9 notebook-5.7.8 numpy-1.18.5 openmined.threepio-0.2.0 phe-1.4.0 psutil-5.7.0 pyee-8.1.0 pylibsrtp-0.6.8 python-engineio-4.0.1 python-socketio-5.1.0 requests-2.22.0 requests-toolbelt-0.9.1 shaloop-0.2.1a11 syft-0.2.9 syft-proto-0.5.3 tblib-1.6.0 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "psutil",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE4orNu36t4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6366e15a-7cd8-44df-bfa8-41cbfdb9bdca"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0DG8Ckz9PNh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords  # noqa: F401\n",
        "\n",
        "STOPWORDS = stopwords.words('english')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dqEHoJs5mzV"
      },
      "source": [
        "#data = pd.read_csv(\"/content/fedhospital.tsv\", sep=\"\\t\", header=None, names=[\"label\", \"sms\"])\n",
        "df = pd.read_csv('/content/drive/MyDrive/Federated Learning/dataset/cancer_data.tsv', sep = '\\t', header=None, names=[\"label\", \"sms\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtKwXZUR62uy"
      },
      "source": [
        "#clin_trial = pd.DataFrame(np.array(data).reshape(2000,2), columns=['label', 'describe'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUH7E1Ik623e"
      },
      "source": [
        "df.columns = ['reviews', 'cat']\n",
        "mind = {'no':'no', 'no ': 'no', ' no':'no', 'yes':'yes', 'yes ':'yes'}\n",
        "df['cat'] = [mind[x] for x in df['cat']]\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "def remove_links(tweet):\n",
        "    '''Takes a string and removes web links from it'''\n",
        "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
        "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # rempve bitly links\n",
        "    tweet = tweet.strip('[link]') # remove [links]\n",
        "    return tweet\n",
        "\n",
        "df['reviews']=df['reviews'].apply(lambda x: remove_links(x))\n",
        "def remove_users(tweet):\n",
        "    '''Takes a string and removes retweet and @user information'''\n",
        "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
        "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
        "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
        "    return tweet\n",
        "\n",
        "df['reviews']=df['reviews'].apply(lambda x: remove_users(x))\n",
        "\n",
        "def remove_punc(text):\n",
        "    no_punc = ''.join([c for c in text if c not in string.punctuation])\n",
        "    return no_punc\n",
        "\n",
        "df['reviews']=df['reviews'].apply(lambda x: remove_punc(x))\n",
        "df = df[['cat', 'reviews']]\n",
        "#column_names = [\"cat\", \"reviews\"]\n",
        "#df = df.reindex(columns=column_names)\n",
        "\n",
        "df.rename(columns={\"cat\": \"label\", \"reviews\": \"sms\"},inplace=True)\n",
        "\n",
        "data=df\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGcGe8uQ6CSN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "f214231d-60ec-46e3-bcc2-2a23c4219d8d"
      },
      "source": [
        "data\n",
        "#study"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no</td>\n",
              "      <td>Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids alright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no</td>\n",
              "      <td>you could give GameStop the cure to cancer amp they’d offer you 389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>This last year has been the hardest of my life  to all the cancer researchers doctors nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients you are my heroes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no</td>\n",
              "      <td>The year is 2043 You opened your newspaper and read the headlines   World Health Organization releases a cure for Cancer  Global warming threat eliminated   Enrile celebrating his birthday  Pengui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no</td>\n",
              "      <td>Here we go again Yet another dubious cancer cure video Watch to the end and see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>no</td>\n",
              "      <td>amp  next   in minutes            home to the  and    CANCER CURE Cancer is predicta…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>no</td>\n",
              "      <td>The Donald could come up with a cure for cancer and theyd still hate him</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1504</th>\n",
              "      <td>no</td>\n",
              "      <td>In my unpopular opinion the whole “I don’t wanna talk to a stranger about my problems” is an irresponsible and bs excuse to avoid getting the help you need You wouldn’t ask your family for support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1505</th>\n",
              "      <td>no</td>\n",
              "      <td>Presumably if May announced that she’d singlehandedly got rid of poverty found a cure for cancer and wiped out the national debt     would instantly believe that too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>no</td>\n",
              "      <td>1 Autism is a spectrum There are higher functioning people than your brother than can comprehend politics and lower functioning as well 2 I dont take moral lessons from shitty indieband groupi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1507 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                                                                                                                                                                                      sms\n",
              "0       no                                                                                               Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids alright \n",
              "1       no                                                                                                                                     you could give GameStop the cure to cancer amp they’d offer you 389 \n",
              "2       no  This last year has been the hardest of my life  to all the cancer researchers doctors nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients you are my heroes...\n",
              "3       no  The year is 2043 You opened your newspaper and read the headlines   World Health Organization releases a cure for Cancer  Global warming threat eliminated   Enrile celebrating his birthday  Pengui...\n",
              "4       no                                                                                                                         Here we go again Yet another dubious cancer cure video Watch to the end and see \n",
              "...    ...                                                                                                                                                                                                      ...\n",
              "1502    no                                                                                                                    amp  next   in minutes            home to the  and    CANCER CURE Cancer is predicta…\n",
              "1503    no                                                                                                                                 The Donald could come up with a cure for cancer and theyd still hate him\n",
              "1504    no  In my unpopular opinion the whole “I don’t wanna talk to a stranger about my problems” is an irresponsible and bs excuse to avoid getting the help you need You wouldn’t ask your family for support...\n",
              "1505    no                             Presumably if May announced that she’d singlehandedly got rid of poverty found a cure for cancer and wiped out the national debt     would instantly believe that too       \n",
              "1506    no      1 Autism is a spectrum There are higher functioning people than your brother than can comprehend politics and lower functioning as well 2 I dont take moral lessons from shitty indieband groupi...\n",
              "\n",
              "[1507 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZR1kc-55m5q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "9a58a2bd-f45d-41a5-cfb9-ed79b32ea46b"
      },
      "source": [
        "data\n",
        "#condition\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no</td>\n",
              "      <td>Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids alright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>no</td>\n",
              "      <td>you could give GameStop the cure to cancer amp they’d offer you 389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>no</td>\n",
              "      <td>This last year has been the hardest of my life  to all the cancer researchers doctors nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients you are my heroes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no</td>\n",
              "      <td>The year is 2043 You opened your newspaper and read the headlines   World Health Organization releases a cure for Cancer  Global warming threat eliminated   Enrile celebrating his birthday  Pengui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no</td>\n",
              "      <td>Here we go again Yet another dubious cancer cure video Watch to the end and see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>no</td>\n",
              "      <td>amp  next   in minutes            home to the  and    CANCER CURE Cancer is predicta…</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>no</td>\n",
              "      <td>The Donald could come up with a cure for cancer and theyd still hate him</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1504</th>\n",
              "      <td>no</td>\n",
              "      <td>In my unpopular opinion the whole “I don’t wanna talk to a stranger about my problems” is an irresponsible and bs excuse to avoid getting the help you need You wouldn’t ask your family for support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1505</th>\n",
              "      <td>no</td>\n",
              "      <td>Presumably if May announced that she’d singlehandedly got rid of poverty found a cure for cancer and wiped out the national debt     would instantly believe that too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1506</th>\n",
              "      <td>no</td>\n",
              "      <td>1 Autism is a spectrum There are higher functioning people than your brother than can comprehend politics and lower functioning as well 2 I dont take moral lessons from shitty indieband groupi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1507 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                                                                                                                                                                                      sms\n",
              "0       no                                                                                               Yall creating life and cloning animals but want us to believe there is no cure for Cancer or Aids alright \n",
              "1       no                                                                                                                                     you could give GameStop the cure to cancer amp they’d offer you 389 \n",
              "2       no  This last year has been the hardest of my life  to all the cancer researchers doctors nurses and caregivers who are so selflessly dedicated to finding a cure and healing patients you are my heroes...\n",
              "3       no  The year is 2043 You opened your newspaper and read the headlines   World Health Organization releases a cure for Cancer  Global warming threat eliminated   Enrile celebrating his birthday  Pengui...\n",
              "4       no                                                                                                                         Here we go again Yet another dubious cancer cure video Watch to the end and see \n",
              "...    ...                                                                                                                                                                                                      ...\n",
              "1502    no                                                                                                                    amp  next   in minutes            home to the  and    CANCER CURE Cancer is predicta…\n",
              "1503    no                                                                                                                                 The Donald could come up with a cure for cancer and theyd still hate him\n",
              "1504    no  In my unpopular opinion the whole “I don’t wanna talk to a stranger about my problems” is an irresponsible and bs excuse to avoid getting the help you need You wouldn’t ask your family for support...\n",
              "1505    no                             Presumably if May announced that she’d singlehandedly got rid of poverty found a cure for cancer and wiped out the national debt     would instantly believe that too       \n",
              "1506    no      1 Autism is a spectrum There are higher functioning people than your brother than can comprehend politics and lower functioning as well 2 I dont take moral lessons from shitty indieband groupi...\n",
              "\n",
              "[1507 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyy5srMfGNSe"
      },
      "source": [
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "\n",
        "def tokenize(text, word_to_idx):\n",
        "    tokens = []\n",
        "    for word in text.split():\n",
        "        tokens.append(word_to_idx[word])\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def pad_and_truncate(messages, max_length=0):\n",
        "    features = np.zeros((len(messages), max_length), dtype=int)\n",
        "    for i, sms in enumerate(messages):\n",
        "        if len(sms):\n",
        "            features[i, -len(sms) :] = sms[:max_length]\n",
        "    return features\n",
        "\n",
        "\n",
        "def main():\n",
        "    \n",
        "    #data = pd.read_csv(\"/content/datafd\", sep=\"\\t\", header=None, names=[\"label\", \"sms\"])\n",
        "    data.sms = data.sms.apply(clean_text)\n",
        "    words = set((\" \".join(data.sms)).split())\n",
        "    word_to_idx = {word: i for i, word in enumerate(words, 1)}\n",
        "    tokens = data.sms.apply(lambda x: tokenize(x, word_to_idx))\n",
        "    inputs = pad_and_truncate(tokens)\n",
        "\n",
        "    labels = np.array((data.label == \"no\").astype(int))\n",
        "\n",
        "    np.save(\"/content/labels.npy\", labels)\n",
        "    np.save(\"/content/inputs.npy\", inputs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oE8ivngGYyY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "\n",
        "        # reset gate\n",
        "        self.fc_ir = nn.Linear(input_size, hidden_size, bias=bias)\n",
        "        self.fc_hr = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        # update gate\n",
        "        self.fc_iz = nn.Linear(input_size, hidden_size, bias=bias)\n",
        "        self.fc_hz = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        # new gate\n",
        "        self.fc_in = nn.Linear(input_size, hidden_size, bias=bias)\n",
        "        self.fc_hn = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        self.init_parameters()\n",
        "\n",
        "    def init_parameters(self):\n",
        "        std = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        x = x.view(-1, x.shape[1])\n",
        "\n",
        "        i_r = self.fc_ir(x)\n",
        "        h_r = self.fc_hr(h)\n",
        "        i_z = self.fc_iz(x)\n",
        "        h_z = self.fc_hz(h)\n",
        "        i_n = self.fc_in(x)\n",
        "        h_n = self.fc_hn(h)\n",
        "\n",
        "        resetgate = F.sigmoid(i_r + h_r)\n",
        "        inputgate = F.sigmoid(i_z + h_z)\n",
        "        newgate = F.tanh(i_n + (resetgate * h_n))\n",
        "\n",
        "        hy = newgate + inputgate * (h - newgate)\n",
        "        \n",
        "        return hy\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, output_size=1, embedding_dim=50, hidden_dim=10, bias=True, dropout=0.2\n",
        "    ):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # GRU Cell\n",
        "        self.gru_cell = GRUCell(embedding_dim, hidden_dim)\n",
        "        # Fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        # Sigmoid layer\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Deal with cases were the current batch_size is different from general batch_size\n",
        "        # It occurrs at the end of iteration with the Dataloaders\n",
        "        if h.shape[0] != batch_size:\n",
        "            h = h[:batch_size, :].contiguous()\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # GRU cells\n",
        "        for t in range(x.shape[1]):\n",
        "            h = self.gru_cell(x[:, t, :], h)\n",
        "\n",
        "        # Output corresponds to the last hidden state\n",
        "        out = h.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # Dropout and fully-connected layers\n",
        "        out = self.dropout(out)\n",
        "        sig_out = self.sigmoid(self.fc(out))\n",
        "\n",
        "        return sig_out, h"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFfOB478p_9j"
      },
      "source": [
        "# Recurrent neural network (many-to-one)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, num_classes=2):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states \n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "  \n",
        "class RNN_m(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, output_size=1, embedding_dim=50, hidden_dim=10, bias=True, dropout=0.2\n",
        "    ):\n",
        "        super(RNN_m, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # RNN\n",
        "        self.RNN = RNN(embedding_dim, hidden_dim)\n",
        "        # Fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        # Sigmoid layer\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Deal with cases were the current batch_size is different from general batch_size\n",
        "        # It occurrs at the end of iteration with the Dataloaders\n",
        "        if h.shape[0] != batch_size:\n",
        "            h = h[:batch_size, :].contiguous()\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # GRU cells\n",
        "        for t in range(x.shape[1]):\n",
        "            h = self.RNN_m(x[:, t, :], h)\n",
        "\n",
        "        # Output corresponds to the last hidden state\n",
        "        out = h.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # Dropout and fully-connected layers\n",
        "        out = self.dropout(out)\n",
        "        sig_out = self.sigmoid(self.fc(out))\n",
        "\n",
        "        return sig_out, h"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReB9I0kpqAID"
      },
      "source": [
        "# Bidirectional recurrent neural network (many-to-one)\n",
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=2, num_classes=2):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial states\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "class BiRNN_m(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, output_size=1, embedding_dim=50, hidden_dim=10, bias=True, dropout=0.2\n",
        "    ):\n",
        "        super(BiRNN_m, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # RNN\n",
        "        self.RNN = RNN(embedding_dim, hidden_dim)\n",
        "        # Fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        # Sigmoid layer\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Deal with cases were the current batch_size is different from general batch_size\n",
        "        # It occurrs at the end of iteration with the Dataloaders\n",
        "        if h.shape[0] != batch_size:\n",
        "            h = h[:batch_size, :].contiguous()\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # GRU cells\n",
        "        for t in range(x.shape[1]):\n",
        "            h = self.gru_cell(x[:, t, :], h)\n",
        "\n",
        "        # Output corresponds to the last hidden state\n",
        "        out = h.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # Dropout and fully-connected layers\n",
        "        out = self.dropout(out)\n",
        "        sig_out = self.sigmoid(self.fc(out))\n",
        "\n",
        "        return sig_out, h"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yWUdlwtqfGo"
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "\tdef __init__(self, vocab_size, embedding_dim, hidden_dim=2, output_size=1):\n",
        "\n",
        "\t\tsuper(LSTMClassifier, self).__init__()\n",
        "\n",
        "\t\tself.embedding_dim = embedding_dim\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\t\tself.vocab_size = vocab_size\n",
        "\n",
        "\t\tself.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\t\tself.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1)\n",
        "\n",
        "\t\tself.hidden2out = nn.Linear(hidden_dim, output_size)\n",
        "\t\tself.softmax = nn.LogSoftmax()\n",
        "\n",
        "\t\tself.dropout_layer = nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "\tdef init_hidden(self, batch_size):\n",
        "\t\treturn(autograd.Variable(torch.randn(1, batch_size, self.hidden_dim)),\n",
        "\t\t\t\t\t\tautograd.Variable(torch.randn(1, batch_size, self.hidden_dim)))\n",
        "\n",
        "\n",
        "\tdef forward(self, batch, lengths):\n",
        "\t\t\n",
        "\t\tself.hidden = self.init_hidden(batch.size(-1))\n",
        "\n",
        "\t\tembeds = self.embedding(batch)\n",
        "\t\tpacked_input = pack_padded_sequence(embeds, lengths)\n",
        "\t\toutputs, (ht, ct) = self.lstm(packed_input, self.hidden)\n",
        "\n",
        "\t\t# ht is the last hidden state of the sequences\n",
        "\t\t# ht = (1 x batch_size x hidden_dim)\n",
        "\t\t# ht[-1] = (batch_size x hidden_dim)\n",
        "\t\toutput = self.dropout_layer(ht[-1])\n",
        "\t\toutput = self.hidden2out(output)\n",
        "\t\toutput = self.softmax(output)\n",
        "\n",
        "\t\treturn output\n",
        "\n",
        "class  LSTMClassifier_m(nn.Module):\n",
        "    def __init__(\n",
        "        self, vocab_size, output_size=1, embedding_dim=50, hidden_dim=10, bias=True, dropout=0.2\n",
        "    ):\n",
        "        super(LSTMClassifier_m, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        #  LSTMClassifier\n",
        "        self.LSTMClassifier = LSTMClassifier(embedding_dim, hidden_dim)\n",
        "        # Fully-connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        # Sigmoid layer\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, h):\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Deal with cases were the current batch_size is different from general batch_size\n",
        "        # It occurrs at the end of iteration with the Dataloaders\n",
        "        if h.shape[0] != batch_size:\n",
        "            h = h[:batch_size, :].contiguous()\n",
        "\n",
        "        # Apply embedding\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # GRU cells\n",
        "        for t in range(x.shape[1]):\n",
        "            h = self.gru_cell(x[:, t, :], h)\n",
        "\n",
        "        # Output corresponds to the last hidden state\n",
        "        out = h.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # Dropout and fully-connected layers\n",
        "        out = self.dropout(out)\n",
        "        sig_out = self.sigmoid(self.fc(out))\n",
        "\n",
        "        return sig_out, h\t\t"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PQkyABUrAbV"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdnsiykktscj"
      },
      "source": [
        "#federated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s2ZygvGHN9-"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-w4PbIBcYvU"
      },
      "source": [
        "inputs = np.load('/content/inputs.npy')\n",
        "labels = np.load('/content/labels.npy')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEL2szJxHYD0"
      },
      "source": [
        "VOCAB_SIZE = 57"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLv9We2YH3aW"
      },
      "source": [
        "# Training params\n",
        "EPOCHS = 5\n",
        "CLIP = 5 # gradient clipping - to avoid gradient explosion (frequent in RNNs)\n",
        "lr = 0.1\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Model params\n",
        "EMBEDDING_DIM = 50\n",
        "HIDDEN_DIM = 10\n",
        "DROPOUT = 0.2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv-RheD1H6vy"
      },
      "source": [
        "import syft as sy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsicMMqiIDO7"
      },
      "source": [
        "labels = torch.tensor(labels)\n",
        "inputs = torch.tensor(inputs)\n",
        "\n",
        "# splitting training and test data\n",
        "pct_test = 0.2\n",
        "\n",
        "train_labels = labels[:-int(len(labels)*pct_test)]\n",
        "train_inputs = inputs[:-int(len(labels)*pct_test)]\n",
        "\n",
        "test_labels = labels[-int(len(labels)*pct_test):]\n",
        "test_inputs = inputs[-int(len(labels)*pct_test):]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjyJbJ_yJIbz"
      },
      "source": [
        "# Hook that extends the Pytorch library to enable all computations with pointers of tensors sent to other workers\n",
        "hook = sy.TorchHook(torch)\n",
        "\n",
        "# Creating 2 virtual workers\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "anne = sy.VirtualWorker(hook, id=\"anne\")\n",
        "\n",
        "# threshold indexes for dataset split (one half for Bob, other half for Anne)\n",
        "train_idx = 800\n",
        "test_idx = 200\n",
        "\n",
        "# Sending toy datasets to virtual workers\n",
        "bob_train_dataset = sy.BaseDataset(train_inputs[:train_idx], train_labels[:train_idx]).send(bob)\n",
        "anne_train_dataset = sy.BaseDataset(train_inputs[train_idx:], train_labels[train_idx:]).send(anne)\n",
        "bob_test_dataset = sy.BaseDataset(test_inputs[:test_idx], test_labels[:test_idx]).send(bob)\n",
        "anne_test_dataset = sy.BaseDataset(test_inputs[test_idx:], test_labels[test_idx:]).send(anne)\n",
        "\n",
        "# Creating federated datasets, an extension of Pytorch TensorDataset class\n",
        "federated_train_dataset = sy.FederatedDataset([bob_train_dataset, anne_train_dataset])\n",
        "federated_test_dataset = sy.FederatedDataset([bob_test_dataset, anne_test_dataset])\n",
        "\n",
        "# Creating federated dataloaders, an extension of Pytorch DataLoader class\n",
        "federated_train_loader = sy.FederatedDataLoader(federated_train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "federated_test_loader = sy.FederatedDataLoader(federated_test_dataset, shuffle=False, batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkp21edNJOJo"
      },
      "source": [
        "# Initiating the model\n",
        "model = GRU(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = RNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = BiRNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = LSTMClassifier_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfHn7ccxQBxo"
      },
      "source": [
        "\"\"\"\n",
        "# Initiating the model\n",
        "#model = GRU(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "model = RNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = BiRNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = LSTMClassifier_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-HhWh6XQB6H"
      },
      "source": [
        "\"\"\"\n",
        "# Initiating the model\n",
        "#model = GRU(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = RNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "model = BiRNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = LSTMClassifier_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzt9KX2EQB_p"
      },
      "source": [
        "\"\"\"\n",
        "# Initiating the model\n",
        "#model = GRU(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = RNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "#model = BiRNN_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "model = LSTMClassifier_m(vocab_size=VOCAB_SIZE, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5hUYhEUJZ1E"
      },
      "source": [
        "# Defining loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUphjELaKQZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a4f8db-ec96-44c7-ce19-8015b68c950e"
      },
      "source": [
        "\n",
        "%%time\n",
        "for e in range(EPOCHS):\n",
        "    \n",
        "    ######### Training ##########\n",
        "    \n",
        "    losses = []\n",
        "    # Batch loop\n",
        "    for inputs, labels in federated_train_loader:\n",
        "        # Location of current batch\n",
        "        worker = inputs.location\n",
        "        # Initialize hidden state and send it to worker\n",
        "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).send(worker)\n",
        "        # Send model to current worker\n",
        "        model.send(worker)\n",
        "        # Setting accumulated gradients to zero before backward step\n",
        "        optimizer.zero_grad()\n",
        "        # Output from the model\n",
        "        output, _ = model(inputs, h)\n",
        "        # Calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # Clipping the gradient to avoid explosion\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "        # Backpropagation step\n",
        "        optimizer.step() \n",
        "        # Get the model back to the local worker\n",
        "        model.get()\n",
        "        losses.append(loss.get())\n",
        "    \n",
        "    ######## Evaluation ##########\n",
        "    \n",
        "    # Model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_preds = []\n",
        "        test_labels_list = []\n",
        "        eval_losses = []\n",
        "\n",
        "        for inputs, labels in federated_test_loader:\n",
        "            # get current location\n",
        "            worker = inputs.location\n",
        "            # Initialize hidden state and send it to worker\n",
        "            h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).send(worker)    \n",
        "            # Send model to worker\n",
        "            model.send(worker)\n",
        "            \n",
        "            output, _ = model(inputs, h)\n",
        "            loss = criterion(output.squeeze(), labels.float())\n",
        "            eval_losses.append(loss.get())\n",
        "            preds = output.squeeze().get()\n",
        "            test_preds += list(preds.numpy())\n",
        "            test_labels_list += list(labels.get().numpy().astype(int))\n",
        "            # Get the model back to the local worker\n",
        "            model.get()\n",
        "        \n",
        "        score = roc_auc_score(test_labels_list, test_preds)\n",
        "    \n",
        "    print(\"Epoch {}/{}...  \\\n",
        "    AUC: {:.3%}...  \\\n",
        "    Training loss: {:.5f}...  \\\n",
        "    Validation loss: {:.5f}\".format(e+1, EPOCHS, score, sum(losses)/len(losses), sum(eval_losses)/len(eval_losses)))\n",
        "    \n",
        "    model.train()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5...      AUC: 50.000%...      Training loss: 0.56920...      Validation loss: 0.44751\n",
            "Epoch 2/5...      AUC: 50.000%...      Training loss: 0.44627...      Validation loss: 0.38585\n",
            "Epoch 3/5...      AUC: 50.000%...      Training loss: 0.42006...      Validation loss: 0.36713\n",
            "Epoch 4/5...      AUC: 50.000%...      Training loss: 0.41184...      Validation loss: 0.35948\n",
            "Epoch 5/5...      AUC: 50.000%...      Training loss: 0.40894...      Validation loss: 0.35596\n",
            "CPU times: user 16 s, sys: 514 ms, total: 16.5 s\n",
            "Wall time: 16.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
